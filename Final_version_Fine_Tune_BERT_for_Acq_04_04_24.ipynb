{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1xF84-5GWXz_JTsk6W_jG3a6r6biUFQJI","timestamp":1712231110588},{"file_id":"1myefdTBpaN8w8pm42IJRZbTB549AlIMv","timestamp":1696253845637},{"file_id":"18rLyqLGCScheO51qGwFIBrUAC527LOuZ","timestamp":1695654288123},{"file_id":"1CUoWyRp0FrzpQUkS37qUJmY1hsotKmeO","timestamp":1695238591843}],"gpuType":"T4","machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f8040ae3181746b58cfcfd2d5f4d48f7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_eeab81d9a4ac418e8dc88f083c9360b6","IPY_MODEL_95147f0dea4446a39b07e670af6ccc47","IPY_MODEL_46d89851d8bc4d98a6eeb93e42729e88"],"layout":"IPY_MODEL_5ba0ef44405d480ca144a60e2cb7e849"}},"eeab81d9a4ac418e8dc88f083c9360b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6e4001acaad649888b46fce0a84987ab","placeholder":"​","style":"IPY_MODEL_3d525b2e453d45529f3e831e5b249e8b","value":"tokenizer_config.json: 100%"}},"95147f0dea4446a39b07e670af6ccc47":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb70c991121e424da803ed9ec0505005","max":48,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ca213cf4a024adeb241edfbf5a11824","value":48}},"46d89851d8bc4d98a6eeb93e42729e88":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c312c4393c24a5a953f627e0a9a0465","placeholder":"​","style":"IPY_MODEL_5283d349779149e0925df4d926056f68","value":" 48.0/48.0 [00:00&lt;00:00, 4.52kB/s]"}},"5ba0ef44405d480ca144a60e2cb7e849":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e4001acaad649888b46fce0a84987ab":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d525b2e453d45529f3e831e5b249e8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb70c991121e424da803ed9ec0505005":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ca213cf4a024adeb241edfbf5a11824":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7c312c4393c24a5a953f627e0a9a0465":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5283d349779149e0925df4d926056f68":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fb6dd290767d481b9f9ee5b25a85d56a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cffe44ea7e447a1a0df4641be084dd9","IPY_MODEL_26117837985a41b9afca07d78af2d194","IPY_MODEL_c26052745ed049afaf8c7d7d2cb69f06"],"layout":"IPY_MODEL_64caac7518d940798f142627a15119e3"}},"3cffe44ea7e447a1a0df4641be084dd9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e015228d8ce94c1faaa6ba7ad9d39366","placeholder":"​","style":"IPY_MODEL_0cc03a438e7d49b6962214daa2480af3","value":"vocab.txt: 100%"}},"26117837985a41b9afca07d78af2d194":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb95aa764c8d49e1bfd67b11faf6f29a","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_93680ff6708a4d3ea8f5c41c51641962","value":231508}},"c26052745ed049afaf8c7d7d2cb69f06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d5f2d1b47864971bf8ffe8534cbc51b","placeholder":"​","style":"IPY_MODEL_f27dd7a50e9d4eee9c3f45d473ba109b","value":" 232k/232k [00:00&lt;00:00, 4.08MB/s]"}},"64caac7518d940798f142627a15119e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e015228d8ce94c1faaa6ba7ad9d39366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cc03a438e7d49b6962214daa2480af3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb95aa764c8d49e1bfd67b11faf6f29a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"93680ff6708a4d3ea8f5c41c51641962":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0d5f2d1b47864971bf8ffe8534cbc51b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f27dd7a50e9d4eee9c3f45d473ba109b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"066d5558c7eb4aa1b4eecd706c0ed465":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c94591d55cd247ee85ef00e990e12a27","IPY_MODEL_b8012f42ed3547669f253ed1510353df","IPY_MODEL_5fc9f0af5191429694b133d0aa2b953c"],"layout":"IPY_MODEL_719f209e0ad447088d2610cc17583893"}},"c94591d55cd247ee85ef00e990e12a27":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e68a4b3a30cc41a49b2cb8fba7023fdd","placeholder":"​","style":"IPY_MODEL_e6868a7ce0c44553a3e410eff5282e01","value":"tokenizer.json: 100%"}},"b8012f42ed3547669f253ed1510353df":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_24e21c3c91184a3c95c7434e14ce6d87","max":466062,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ce46aa6aec5f43af8ca4fcd70e7092a7","value":466062}},"5fc9f0af5191429694b133d0aa2b953c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3534a0f0db4468f98b62ef0baaab623","placeholder":"​","style":"IPY_MODEL_2d2b5c756cff420494b394ec5db8b200","value":" 466k/466k [00:00&lt;00:00, 7.87MB/s]"}},"719f209e0ad447088d2610cc17583893":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e68a4b3a30cc41a49b2cb8fba7023fdd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6868a7ce0c44553a3e410eff5282e01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"24e21c3c91184a3c95c7434e14ce6d87":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ce46aa6aec5f43af8ca4fcd70e7092a7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3534a0f0db4468f98b62ef0baaab623":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d2b5c756cff420494b394ec5db8b200":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5e5e5ae6c7146b1bf54af728a1154cf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3992c14ffb24491878a1abaf0276c6c","IPY_MODEL_2e717341ef974c8fa56faa92c66ecf51","IPY_MODEL_c3d0e04c92644dc6a88ce2b2bb917992"],"layout":"IPY_MODEL_470e66301e9e43bfb45c38a88d7b5306"}},"b3992c14ffb24491878a1abaf0276c6c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5d480b9d22940a494cf894a52950f22","placeholder":"​","style":"IPY_MODEL_36e9b8e9a92b4e32a240f10446e93e50","value":"config.json: 100%"}},"2e717341ef974c8fa56faa92c66ecf51":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_035d36b25e7a49f0a1b41858731d15fd","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ae8fb7c8b6e148d8868aad68a55a23cd","value":570}},"c3d0e04c92644dc6a88ce2b2bb917992":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90cc60cf7b984da597ffd30362fe2420","placeholder":"​","style":"IPY_MODEL_059beb2bb28b4b1b892e8146a5a6ec27","value":" 570/570 [00:00&lt;00:00, 50.3kB/s]"}},"470e66301e9e43bfb45c38a88d7b5306":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5d480b9d22940a494cf894a52950f22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"36e9b8e9a92b4e32a240f10446e93e50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"035d36b25e7a49f0a1b41858731d15fd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ae8fb7c8b6e148d8868aad68a55a23cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90cc60cf7b984da597ffd30362fe2420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"059beb2bb28b4b1b892e8146a5a6ec27":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/BERT/Custom_Named_Entity_Recognition_with_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UwdMkvV_3cH0","executionInfo":{"status":"ok","timestamp":1714407779114,"user_tz":-60,"elapsed":25210,"user":{"displayName":"Younes Mechqrane","userId":"08352357065262961208"}},"outputId":"1e993fff-82ee-4306-eb2d-28b5289f8c41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Install Required Libraries\n","!pip install transformers[torch] datasets accelerate\n","!pip install transformers seqeval[gpu]"],"metadata":{"id":"FvLPC-_RRqVd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714407795200,"user_tz":-60,"elapsed":10675,"user":{"displayName":"Younes Mechqrane","userId":"08352357065262961208"}},"outputId":"965ca362-67b9-4ca4-e50f-b90c801cdca8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.29.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n","Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n","Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.0.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (8.9.2.26)\n","Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.3.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.0.2.54)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (10.3.2.106)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (11.4.5.107)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.0.106)\n","Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.19.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (12.1.105)\n","Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n","Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch]) (12.4.127)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.40.0)\n","Requirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.10/dist-packages (1.2.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.4)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.22.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval[gpu]) (1.2.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.4.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n"]}]},{"cell_type":"code","source":["!pip install matplotlib"],"metadata":{"id":"hp8oMqLck_qM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1714407803874,"user_tz":-60,"elapsed":5427,"user":{"displayName":"Younes Mechqrane","userId":"08352357065262961208"}},"outputId":"ff360f20-a663-4228-89a5-859d4f67a49a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n","Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"]}]},{"cell_type":"code","source":["from transformers import BertTokenizer, BertTokenizerFast\n","import torch\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import DataLoader\n","from transformers import BertTokenizerFast, BertModel\n","import torch.optim as optim\n","import json\n","import ast\n","import random\n","from sklearn.metrics import accuracy_score\n","from torch import cuda\n","import re\n","\n","\n","maxlen=50"],"metadata":{"id":"1VXyaJ5VAL8i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = 'cuda' if cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pk4avF1LE3l6","executionInfo":{"status":"ok","timestamp":1714407813887,"user_tz":-60,"elapsed":3,"user":{"displayName":"Younes Mechqrane","userId":"08352357065262961208"}},"outputId":"fa587b00-6956-4eb8-d3e1-c5a4536a0049"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"code","source":["\n","filename='synthetic_data_27_12_23.txt'\n","# Initialize an empty list to store the dictionaries\n","data= []\n","\n","# Open the file and read each line\n","with open(filename, 'r') as file:\n","    for line in file:\n","        # Parse the JSON string to a Python dictionary and append to the list\n","        data.append(json.loads(line.strip()))\n","\n","da = data[:5]\n","print(da)\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yLhetZ7OM2Ig","executionInfo":{"status":"ok","timestamp":1714407840661,"user_tz":-60,"elapsed":1480,"user":{"displayName":"Younes Mechqrane","userId":"08352357065262961208"}},"outputId":"cdc5a55d-53cf-45c2-a5ca-9d8970df8323"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[{'text': 'Mandate the uniqueness of values within X10 X60 X8 X1 X40 X7 X21 X31 X45', 'labels': '[0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]', 'task_name': 'token_classification'}, {'text': 'Mandate the uniqueness of values within X10 X60 X8 X1 X40 X7 X21 X31 X45', 'labels': '[0]', 'task_name': 'sequence_classification'}, {'text': 'Demand that all within X95 X88 X27 X85 X33 X30 X74 X39 X86 are differently characterized', 'labels': '[0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 0, 0]', 'task_name': 'token_classification'}, {'text': 'Demand that all within X95 X88 X27 X85 X33 X30 X74 X39 X86 are differently characterized', 'labels': '[0]', 'task_name': 'sequence_classification'}, {'text': 'Confirm the separate identity of each of X65 X95 X78 X76 X51 X1 X52 X37 X89', 'labels': '[0, 0, 0, 0, 0, 0, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]', 'task_name': 'token_classification'}]\n"]}]},{"cell_type":"code","source":["sequence_classification_data = [ d for d in data if d['task_name'] == 'sequence_classification' ]\n","token_classification_data = [ d for d in data if d['task_name'] == 'token_classification' ]"],"metadata":{"id":"BQpAIclvAmEt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Shuffle the data\n","random.shuffle(sequence_classification_data)\n","random.shuffle(token_classification_data)\n","\n","# Define the split ratio\n","split_ratio = 0.8  # 80% training, 20% testing\n","\n","# Get the number of data points for training\n","num_train_seq = int(len(sequence_classification_data) * split_ratio)\n","num_train_token = int(len(token_classification_data) * split_ratio)\n","\n","# Split the data\n","train_data_seq = sequence_classification_data[:num_train_seq]\n","test_data_seq = sequence_classification_data[num_train_seq:]\n","\n","train_data_token = token_classification_data[:num_train_token]\n","test_data_token = token_classification_data[num_train_token:]"],"metadata":{"id":"Mu4Fgs52DXJ6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"],"metadata":{"id":"cc9TlP83FvWH","colab":{"base_uri":"https://localhost:8080/","height":249,"referenced_widgets":["f8040ae3181746b58cfcfd2d5f4d48f7","eeab81d9a4ac418e8dc88f083c9360b6","95147f0dea4446a39b07e670af6ccc47","46d89851d8bc4d98a6eeb93e42729e88","5ba0ef44405d480ca144a60e2cb7e849","6e4001acaad649888b46fce0a84987ab","3d525b2e453d45529f3e831e5b249e8b","eb70c991121e424da803ed9ec0505005","8ca213cf4a024adeb241edfbf5a11824","7c312c4393c24a5a953f627e0a9a0465","5283d349779149e0925df4d926056f68","fb6dd290767d481b9f9ee5b25a85d56a","3cffe44ea7e447a1a0df4641be084dd9","26117837985a41b9afca07d78af2d194","c26052745ed049afaf8c7d7d2cb69f06","64caac7518d940798f142627a15119e3","e015228d8ce94c1faaa6ba7ad9d39366","0cc03a438e7d49b6962214daa2480af3","cb95aa764c8d49e1bfd67b11faf6f29a","93680ff6708a4d3ea8f5c41c51641962","0d5f2d1b47864971bf8ffe8534cbc51b","f27dd7a50e9d4eee9c3f45d473ba109b","066d5558c7eb4aa1b4eecd706c0ed465","c94591d55cd247ee85ef00e990e12a27","b8012f42ed3547669f253ed1510353df","5fc9f0af5191429694b133d0aa2b953c","719f209e0ad447088d2610cc17583893","e68a4b3a30cc41a49b2cb8fba7023fdd","e6868a7ce0c44553a3e410eff5282e01","24e21c3c91184a3c95c7434e14ce6d87","ce46aa6aec5f43af8ca4fcd70e7092a7","d3534a0f0db4468f98b62ef0baaab623","2d2b5c756cff420494b394ec5db8b200","c5e5e5ae6c7146b1bf54af728a1154cf","b3992c14ffb24491878a1abaf0276c6c","2e717341ef974c8fa56faa92c66ecf51","c3d0e04c92644dc6a88ce2b2bb917992","470e66301e9e43bfb45c38a88d7b5306","b5d480b9d22940a494cf894a52950f22","36e9b8e9a92b4e32a240f10446e93e50","035d36b25e7a49f0a1b41858731d15fd","ae8fb7c8b6e148d8868aad68a55a23cd","90cc60cf7b984da597ffd30362fe2420","059beb2bb28b4b1b892e8146a5a6ec27"]},"executionInfo":{"status":"ok","timestamp":1714407858776,"user_tz":-60,"elapsed":2772,"user":{"displayName":"Younes Mechqrane","userId":"08352357065262961208"}},"outputId":"29f8546e-9106-4dc0-9a8f-067f85e033da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8040ae3181746b58cfcfd2d5f4d48f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb6dd290767d481b9f9ee5b25a85d56a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"066d5558c7eb4aa1b4eecd706c0ed465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5e5e5ae6c7146b1bf54af728a1154cf"}},"metadata":{}}]},{"cell_type":"code","source":["def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n","    tokenized_sentence = []\n","    labels = []\n","    sentence = sentence.strip()\n","    for word, label in zip(sentence.split(), text_labels):\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = tokenizer.tokenize(word)\n","        n_subwords = len(tokenized_word)\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","        # Add the same label to the new list of labels `n_subwords` times\n","        labels.extend([label] * 1)\n","        labels.extend([label] * (n_subwords -1))\n","\n","    return tokenized_sentence, labels\n","\n","\n","def tokenize_sequence(sentence, tokenizer):\n","    tokenized_sentence = []\n","    sentence = sentence.strip()\n","    for word in sentence.split():\n","        # Tokenize the word and count # of subwords the word is broken into\n","        tokenized_word = tokenizer.tokenize(word)\n","        # Add the tokenized word to the final tokenized word list\n","        tokenized_sentence.extend(tokenized_word)\n","\n","    return tokenized_sentence\n","\n","\n","def process_row( r, tokenizer,maxlen):\n","    #print(\" we will process a row ...................\")\n","    maxlen = maxlen\n","    text = r['text']\n","    task_name=r['task_name']\n","    labels=r['labels']\n","    # Convert string to list of strings\n","    labels = ast.literal_eval(labels)\n","    #print(\" labels \",labels)\n","    # Convert list of strings to list of integers\n","    labels = [int(i) for i in labels]\n","    #print(\" labels after conversion :\",labels)\n","\n","    # step 1: tokenize (and adapt corresponding labels)\n","    if task_name == \"token_classification\":\n","      tokenized_sentence, labels=tokenize_and_preserve_labels(text, labels, tokenizer)\n","    elif task_name == \"sequence_classification\":\n","      tokenized_sentence =tokenize_sequence(text, tokenizer)\n","\n","\n","    # step 2: add special tokens (and corresponding labels)\n","    tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n","    if task_name == \"token_classification\":\n","      labels.insert(0, -100) # add outside label for [CLS] token\n","      labels.append(-100) # add outside label for [SEP] token\n","\n","    #print(tokenized_sentence, labels, task_name)\n","    # step 2-bis: compute mask\n","    mask=[1 for _ in tokenized_sentence ]\n","\n","    # step 3: truncating/padding\n","    initial_length= len(tokenized_sentence)\n","\n","    if (len(tokenized_sentence) > maxlen):\n","    # truncate\n","        tokenized_sentence = tokenized_sentence[:maxlen]\n","        if task_name == \"token_classification\":\n","          labels = labels[:maxlen]\n","        mask = mask[:maxlen]\n","    else:\n","    # pad\n","        tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n","        if task_name == \"token_classification\":\n","          labels = labels + [-100 for _ in range(maxlen - len(labels))]\n","        mask = mask + [0 for _ in range(maxlen - initial_length)]\n","\n","    # step 5: convert tokens to input ids\n","    ids = tokenizer.convert_tokens_to_ids(tokenized_sentence)\n","\n","\n","    # step 6: task name\n","\n","    # step 7:\n","    sequence_classification_labels = -999999\n","    token_classification_labels = []\n","    if task_name == \"sequence_classification\":\n","          sequence_classification_labels = labels[0]\n","          token_classification_labels = torch.tensor([-100 for _ in range(maxlen)])\n","    else:  # token_classification\n","          token_classification_labels= torch.tensor(labels)\n","          sequence_classification_labels = -100\n","\n","\n","    return {\n","            \"tokenized sentence\":tokenized_sentence,\n","            \"input_ids\": ids ,\n","            \"attention_mask\": mask ,\n","            \"sequence_classification_labels\": sequence_classification_labels,\n","            \"token_classification_labels\":token_classification_labels,\n","            \"task_name\": task_name\n","        }\n","\n","\n","def process_batch(batch, tokenizer, maxlen):\n","        batch_size = len(batch)\n","        seq_size = maxlen\n","        input_ids=[]\n","        attention_mask=[]\n","        sequence_classification_labels=[]\n","        token_classification_labels=[]\n","        task_name=[]\n","\n","        for row in batch:\n","          r= process_row( row, tokenizer,maxlen)\n","          input_ids.append(r[\"input_ids\"])\n","          attention_mask.append(r[\"attention_mask\"])\n","          sequence_classification_labels.append(r[\"sequence_classification_labels\"])\n","          token_classification_labels.append(r[\"token_classification_labels\"])\n","          task_name.append(r[\"task_name\"])\n","\n","        return {\n","            \"input_ids\": torch.tensor(input_ids),\n","            \"attention_mask\": torch.tensor(attention_mask),\n","            \"sequence_classification_labels\": torch.tensor(sequence_classification_labels),\n","            \"token_classification_labels\": torch.stack(token_classification_labels),\n","            \"task_name\": task_name\n","        }\n","\n","\n","def generate_balanced_batches(seq_cls_data, token_cls_data, batch_size):\n","    # Shuffle the data at the beginning of each epoch\n","    random.shuffle(seq_cls_data)\n","    random.shuffle(token_cls_data)\n","\n","    # Determine the smaller dataset size\n","    smaller_size = min(len(seq_cls_data), len(token_cls_data))\n","\n","    # Iterate over the data, yielding balanced batches\n","    for i in range(0, smaller_size, batch_size):\n","        # Yield a batch from sequence classification data\n","        yield process_batch( seq_cls_data[i:i+batch_size] , tokenizer, maxlen)\n","\n","        # Yield a batch from token classification data\n","        yield process_batch( token_cls_data[i:i+batch_size] , tokenizer, maxlen)"],"metadata":{"id":"JeF3kUXzI5Lj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define MultiTaskModel\n","class MultiTaskModel(torch.nn.Module):\n","    def __init__(self, num_labels_classification, num_labels_token_classification):\n","        super(MultiTaskModel, self).__init__()\n","        self.bert = BertModel.from_pretrained('bert-base-uncased')\n","        self.classifier = torch.nn.Linear(self.bert.config.hidden_size, num_labels_classification)\n","        self.token_classifier = torch.nn.Linear(self.bert.config.hidden_size, num_labels_token_classification)\n","\n","    def forward(self, input_ids, attention_mask, task_name):\n","        outputs = self.bert(input_ids, attention_mask)\n","        sequence_output = outputs.last_hidden_state\n","        pooler_output = outputs.pooler_output\n","\n","        if task_name == \"sequence_classification\":\n","            return self.classifier(pooler_output)\n","        elif task_name == \"token_classification\":\n","            return self.token_classifier(sequence_output)\n","        else:\n","            raise ValueError(\"Task name should be either 'sequence_classification' or 'token_classification'.\")\n","\n"],"metadata":{"id":"6Hj4gm1izcHe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_model(model, sequence_classification_data, token_classification_data, batch_size, num_labels_token_classification):\n","# Training Loop\n","    running_loss = 0.0\n","    running_accuracy = 0.0\n","    num_batches=0\n","    for batch in generate_balanced_batches(sequence_classification_data, token_classification_data,  batch_size):\n","        #print(\"batch : \",num_batches)\n","        #print(\"batch : \",batch['task_name'])\n","\n","        optimizer.zero_grad()\n","        #print(\" batch: !!!!!!!!!!!!!!!!!!!!!\", batch[\"task_name\"])\n","        task_name = batch[\"task_name\"][0]\n","        input_ids = batch[\"input_ids\"]\n","        attention_mask = batch[\"attention_mask\"]\n","\n","        logits = model(input_ids=input_ids, attention_mask=attention_mask, task_name=task_name)\n","\n","        if task_name == \"sequence_classification\":\n","            labels = batch[\"sequence_classification_labels\"]\n","            loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","            loss = loss_fn(logits, labels)\n","\n","            # Compute accuracy for sequence classification\n","            preds = torch.argmax(logits, dim=1)\n","            acc = accuracy_score(labels.cpu(), preds.cpu())\n","        else:  # token_classification\n","            labels = batch[\"token_classification_labels\"]\n","            loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","            active_loss = attention_mask.view(-1) == 1\n","            active_logits = logits.view(-1, num_labels_token_classification)[active_loss]\n","            active_labels = labels.view(-1)[active_loss]\n","            loss = loss_fn(active_logits, active_labels)\n","\n","            # Compute accuracy for token classification\n","            preds = torch.argmax(active_logits, dim=1)\n","            acc = accuracy_score(active_labels.cpu(), preds.cpu())\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        running_accuracy += acc\n","        num_batches=num_batches+1\n","\n","        #print(f\"   Batch: {num_batches+1}, Task: {task_name}, Loss: {loss.item():.4f}, Accuracy: {acc:.4f}\")\n","\n","    # Compute and print average loss and accuracy for the epoch\n","    avg_loss = running_loss / num_batches\n","    avg_acc = running_accuracy / num_batches\n","    #print(f\"Epoch {epoch+1} Average Loss: {avg_loss:.4f}, Average Accuracy: {avg_acc:.4f}\")\n","\n","    return avg_loss, avg_acc\n"],"metadata":{"id":"dyMzLpOLkly5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate_model(model, sequence_classification_data, token_classification_data, batch_size, num_labels_token_classification):\n","    model.eval()  # Set the model to evaluation mode\n","    total_loss = 0.0\n","    total_accuracy = 0.0\n","    num_batches = 0\n","\n","    with torch.no_grad():  # Disable gradient computation during validation\n","        for batch in generate_balanced_batches(sequence_classification_data, token_classification_data, batch_size):\n","            task_name = batch[\"task_name\"][0]\n","            input_ids = batch[\"input_ids\"]\n","            attention_mask = batch[\"attention_mask\"]\n","\n","            logits = model(input_ids=input_ids, attention_mask=attention_mask, task_name=task_name)\n","\n","            if task_name == \"sequence_classification\":\n","                labels = batch[\"sequence_classification_labels\"]\n","                loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","                loss = loss_fn(logits, labels)\n","\n","                # Compute accuracy for sequence classification\n","                preds = torch.argmax(logits, dim=1)\n","                acc = accuracy_score(labels.cpu(), preds.cpu())\n","            else:  # token_classification\n","                labels = batch[\"token_classification_labels\"]\n","                loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","                active_loss = attention_mask.view(-1) == 1\n","                active_logits = logits.view(-1, num_labels_token_classification)[active_loss]\n","                active_labels = labels.view(-1)[active_loss]\n","                loss = loss_fn(active_logits, active_labels)\n","\n","                # Compute accuracy for token classification\n","                preds = torch.argmax(active_logits, dim=1)\n","                acc = accuracy_score(active_labels.cpu(), preds.cpu())\n","\n","            total_loss += loss.item()\n","            total_accuracy += acc\n","            num_batches += 1\n","\n","    # Calculate average loss and accuracy\n","    avg_loss = total_loss / num_batches\n","    avg_accuracy = total_accuracy / num_batches\n","\n","    return avg_loss, avg_accuracy\n"],"metadata":{"id":"Q5GAKvQVsH0y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import accuracy_score\n","from torch.nn.functional import softmax\n","import torch\n","\n","num_labels_classification=17\n","num_labels_token_classification=11\n","tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","model = MultiTaskModel(num_labels_classification, num_labels_token_classification)\n","#model.load_state_dict(torch.load('/content/drive/MyDrive/model_dict_25_12_23.pth'))\n","\n","optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n","\n"],"metadata":{"id":"7UKBpBuskLG5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size=128\n","# Number of epochs\n","num_epochs = 40\n"],"metadata":{"id":"4rOkQc9Dwf3f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lists to store loss and accuracy values\n","train_losses = []\n","train_accuracies = []\n","val_losses = []\n","val_accuracies = []\n","\n","for epoch in range(num_epochs):\n","    print(f\"Epoch: {epoch+1}\")\n","\n","    # Training the model\n","    running_loss, running_accuracy = train_model(model, train_data_seq, train_data_token, batch_size, num_labels_token_classification)\n","    train_losses.append(running_loss)\n","    train_accuracies.append(running_accuracy)\n","\n","    print(f\"Epoch {epoch+1} Average Loss: {running_loss:.4f}, Average Accuracy: {running_accuracy:.4f}\")\n","\n","    # Validating the model\n","    val_loss, val_accuracy = validate_model(model, test_data_seq, test_data_token, batch_size, num_labels_token_classification)\n","    val_losses.append(val_loss)\n","    val_accuracies.append(val_accuracy)\n","\n","    print(f\"Validation - Epoch: {epoch+1}, Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}\")\n","\n","# Plotting the results\n","plt.figure(figsize=(12, 5))\n","\n","# Plotting loss curves\n","plt.subplot(1, 2, 1)\n","plt.plot(train_losses, label='Training Loss')\n","plt.plot(val_losses, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.title('Loss Curves')\n","\n","# Plotting accuracy curves\n","plt.subplot(1, 2, 2)\n","plt.plot(train_accuracies, label='Training Accuracy')\n","plt.plot(val_accuracies, label='Validation Accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","plt.title('Accuracy Curves')\n","\n","plt.tight_layout()\n","plt.show()"],"metadata":{"id":"D0K1P70qZCpP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Define the file path (change 'My Drive/...' to your desired path)\n","file_path = 'training_results.txt'\n","\n","# Write the data to the file\n","with open(file_path, 'w') as file:\n","    file.write('Epoch,Train Loss,Train Accuracy,Val Loss,Val Accuracy\\n')\n","    for epoch in range(num_epochs):\n","        file.write(f'{epoch+1},{train_losses[epoch]},{train_accuracies[epoch]},{val_losses[epoch]},{val_accuracies[epoch]}\\n')"],"metadata":{"id":"uw6LWh-U5RQD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(model.state_dict(), 'model_dict.pth')\n","\n"],"metadata":{"id":"1Qi640Fb1qfX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from seqeval.metrics import classification_report\n","\n","def test_model(model, sequence_classification_data, token_classification_data, batch_size, num_labels_token_classification):\n","    model.eval()  # Set the model to evaluation mode\n","    total_loss = 0.0\n","    total_accuracy = 0.0\n","    num_batches = 0\n","    eval_preds, eval_labels = [], []\n","\n","    with torch.no_grad():  # Disable gradient computation during validation\n","        for batch in generate_balanced_batches(sequence_classification_data, token_classification_data, batch_size):\n","            task_name = batch[\"task_name\"][0]\n","            print(\"task name\",task_name)\n","            input_ids = batch[\"input_ids\"]\n","            attention_mask = batch[\"attention_mask\"]\n","\n","            logits = model(input_ids=input_ids, attention_mask=attention_mask, task_name=task_name)\n","\n","            if task_name == \"sequence_classification\":\n","                labels = batch[\"sequence_classification_labels\"]\n","                loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","                loss = loss_fn(logits, labels)\n","\n","                # Compute accuracy for sequence classification\n","                preds = torch.argmax(logits, dim=1)\n","\n","                print(\"labels\")\n","                print(labels)\n","                print(\"preds\")\n","                print(preds)\n","\n","                eval_labels.extend(labels)\n","                eval_preds.extend(preds)\n","\n","                acc = accuracy_score(labels.cpu(), preds.cpu())\n","\n","\n","            else:  # token_classification\n","                labels = batch[\"token_classification_labels\"]\n","                loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)\n","                active_loss = attention_mask.view(-1) == 1\n","                active_logits = logits.view(-1, num_labels_token_classification)[active_loss]\n","                active_labels = labels.view(-1)[active_loss]\n","                loss = loss_fn(active_logits, active_labels)\n","\n","                # Compute accuracy for token classification\n","                preds = torch.argmax(active_logits, dim=1)\n","                #print(\" I-----I m hereeeeeeeeeeeeeer\")\n","                #print(active_labels)\n","                #print(\" II----I m hereeeeeeeeeeeeeer\")\n","                #print(preds)\n","                mask = active_labels != -100\n","                filtred_labels = active_labels[mask]\n","                filtred_preds = preds[mask]\n","\n","                #print(\" III----I m hereeeeeeeeeeeeeer\")\n","                #print(filtred_labels)\n","                #print(\" IV----I m hereeeeeeeeeeeeeer\")\n","                #print(filtred_preds)\n","\n","                acc = accuracy_score(active_labels.cpu(), preds.cpu())\n","\n","                eval_labels.extend(filtred_labels)\n","                eval_preds.extend(filtred_preds)\n","\n","            total_loss += loss.item()\n","            total_accuracy += acc\n","            num_batches += 1\n","\n","    # Calculate average loss and accuracy\n","    avg_loss = total_loss / num_batches\n","    avg_accuracy = total_accuracy / num_batches\n","\n","    labels = [\"_\"+str(id.item()) for id in eval_labels]\n","    predictions = [\"_\"+str(id.item()) for id in eval_preds]\n","\n","    print(\"##############\")\n","    print(labels)\n","    print(predictions)\n","\n","\n","    return avg_loss, avg_accuracy, labels, predictions"],"metadata":{"id":"cQ_25qawLp6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["avg_loss, avg_accuracy, labels, predictions = test_model(model, test_data_seq, test_data_token, batch_size, num_labels_token_classification)\n","print(classification_report([labels], [predictions]))\n","print(avg_loss, avg_accuracy)\n"],"metadata":{"id":"rHfx1Xncb6YG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')\n","\n","def bert_find_c(tokenizer, model, sentence, maxlen, num_labels_token_classification):\n","    model.eval()\n","    constraint= {}\n","    #remove ponctuation:\n","    sentence = re.sub(r'[^\\w\\s]', '', sentence)\n","    print(sentence)\n","    inputs = tokenizer(sentence, padding='max_length', truncation=True, max_length=maxlen, return_tensors=\"pt\")\n","    ids = inputs[\"input_ids\"]\n","    mask = inputs[\"attention_mask\"]\n","\n","    # get relation\n","    task_name=\"sequence_classification\"\n","    outputs = model(ids, mask, task_name)\n","    logits = outputs[0]\n","    pred = torch.argmax(logits)\n","\n","    constraint['rel']=pred.item()\n","\n","    # get parameters\n","    task_name=\"token_classification\"\n","    outputs = model(ids, mask, task_name)\n","    logits = outputs[0]\n","    active_logits = logits.view(-1, num_labels_token_classification) # shape (batch_size * seq_len, num_labels)\n","    flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size*seq_len,) - predictions at the token level\n","    tokens = tokenizer.convert_ids_to_tokens(ids.squeeze().tolist())\n","    token_predictions = [i for i in flattened_predictions.cpu().numpy()]\n","    wp_preds = list(zip(tokens, token_predictions)) # list of tuples. Each tuple = (wordpiece, prediction)\n","    #print(\"wp_preds\", wp_preds)\n","    word_level_predictions = []\n","    # we will remove cls, sep and pad\n","    for pair in wp_preds:\n","      if (pair[0] in ['[CLS]', '[SEP]', '[PAD]']):\n","        continue\n","      else:\n","        word_level_predictions.append(pair)\n","\n","    print(\"word_level_predictions\", word_level_predictions)\n","    list_params= {pair[1] for pair in word_level_predictions if pair[1]!=0}\n","    print(\"list params\", list_params)\n","\n","\n","    for i in list_params:\n","      p= [pair[0] for pair in word_level_predictions if pair[1]==i]\n","      param = ''.join(s.replace('##', '') for s in p)\n","      constraint[i]=param\n","\n","    return constraint\n","\n","\n"],"metadata":{"id":"88U3ud3yEW-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Try a sentence for a relation belonging to the vocabulary !!! (see the paper for the vocabulary)\n","\n","sentence = \"The gap between X2 and X0  equals to 4.\"\n","sentence = \"Emphasize the significance of distinct values within X33 X70 X100 X16 X37 X15 X36\"\n","sentence= \"The total sum of X0 X2 X3 X4 needs to be precisely 0\"\n","sentence = \"Demand the absence of repetitions in X29, X55, X17, X45, X36, X60, X73 X68 x100\"\n","\n","\n","constraint= bert_find_c(tokenizer, model, sentence, maxlen, num_labels_token_classification)\n","print(constraint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0Eoq3jLEwlq3","executionInfo":{"status":"ok","timestamp":1714409007369,"user_tz":-60,"elapsed":415,"user":{"displayName":"Younes Mechqrane","userId":"08352357065262961208"}},"outputId":"93bdc430-89d8-4052-8ec4-8c096f99442c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Demand the absence of repetitions in X29 X55 X17 X45 X36 X60 X73 X68 x100\n","word_level_predictions [('demand', 0), ('the', 0), ('absence', 0), ('of', 0), ('repetition', 0), ('##s', 0), ('in', 0), ('x', 1), ('##29', 1), ('x', 2), ('##55', 2), ('x', 3), ('##17', 3), ('x', 4), ('##45', 4), ('x', 5), ('##36', 5), ('x', 6), ('##60', 6), ('x', 7), ('##7', 7), ('##3', 7), ('x', 8), ('##6', 8), ('##8', 8), ('x', 9), ('##100', 9)]\n","list params {1, 2, 3, 4, 5, 6, 7, 8, 9}\n","{'rel': 0, 1: 'x29', 2: 'x55', 3: 'x17', 4: 'x45', 5: 'x36', 6: 'x60', 7: 'x73', 8: 'x68', 9: 'x100'}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"x1RZ_3PvXLlS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Evaluation Mode:** Always remember to set the model to evaluation mode using model.eval() before making predictions, especially when your model uses layers like dropout or batch normalization which have different behavior during training vs testing.\n","\n","**Device Management:** Ensure the model and data are on the same device (CPU or GPU). If you trained your model on a GPU and are loading it on a machine without a GPU, you can map the storage to CPU.\n","\n","model.load_state_dict(torch.load('path_to_save_model_state_dict.pth', map_location=torch.device('cpu')))\n"],"metadata":{"id":"-5EEkE6iMq4B"}}]}